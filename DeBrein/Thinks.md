Мысли

Параметры теста, который рассматривает Сергей Трошков. Это 500 тыс. цепочек, из которых получается 40 млн. узлов. Не так много, но и немало. Это до слияния. Произведем слияние, создадим таблицу имен.  Кроме множества узлов, создадим множество дуг. Получится множество пар { узел, узел }. Это множество индексируем по первому узлу и индексируем по второму узлу. Всего дуг - (почти) ровно 50 млн. По первому индексу будем искать узлы с кратностью...

Сейчас пытаюсь реализовать схему нахождения транзитных цепочек с кратными дугами. Но вначале надо бы разобраться с тем как вообще могла получиться цепочка длиной 159 - это почти удвоенная длина рида. Действительно, есть два рида, которые стыкуются на этой цепочке. Но как, за счет какого сочетания факторов? Решение видимо лежить на границах каких-то участков. Пусь

Измеряю. В тесте reads.txt
495108 lines
39_838_673 word
23_500_652 различных слов
21008101 транзитных узлов
335935 число цепочек
159 максимальная длина цепочки

Затраченное время: 21.4 сек.   

цепочка длиной 159 символов
TTAAACTAGTATTTAATCCCTTCCTGGACCTCAGCATCCTTACCTATAACCTAAGGATACTCATTAATAAATAAGGTCAGTTTCTGACTCCGTCCTTTGGTAGTTCTACTGTTTTGAATTTAAATTCAAACTCCCTAAGTGAAAGTGCAATGATACAAAAGTGAAAGGAAAGCAACTG
найдена стр. № 7900
CTTAAACTAGTATTTAATCCCTTCCTGGACCTCAGCATCCTTACCTATAACCTAAGGATACTCATTAATAAATAAGGTCAGTTTCTGACTCCGTCCTTTGG
стр. № 58474
GTTTCTGACTCCGTCCTTTGGTAGTTCTACTGTTTTGAATTTAAATTCAAACTCCCTAAGTGAAAGTGCAATGATACAAAAGTGAAAGGAAAGCAACTGTG


Надо вернуться к основам. Первая основа - построение графа. Узлы строятся правильно. Строим дуги. Для узла могут быть входящие дуги и могут быть исходящие. Сейчас мы строим только единичные входящие и исходящие дуги. При построении множества узлов, мы имеем состояние, заключающееся в наличии узла current и возможного наличия узла previous. Дуги проводятся ТОЛЬКО если есть previous. Для узла current, мы пытаемся построить ссылку prev, для предыдущего узла, мы пытаемся построить ссылку next. Пытаемся следущим образом: если ссылка null, то строим, если ссылка не null, но такая же, как мы строим, то оставляем ссылку, если ссылка есть, то другая, то делаем ссылку на dummy. 

Посмотрел, вроде граф формируется правильно. Теперь как его использовать? Надо обрабатывать узлы. От узла надо пойти к началу цепочку. Идти надо по обратным (prev) ссылкам. Начальный узел - это узел, у которого есть ровно одна ссылка на следующий (next). После этого, заводится список для цепочки, первый узел отмечается как обработанный и помещается в список. Далее, двигаемся по ссылкам next. Следующий узел отмечается как обработанный и помещается в список.  

### 20190831 07:41
Последний день лета... Как-то бестолково пролетело и я в этом не сильно виноват...

Пытаюсь избавиться от "бяки" в реализации алгоритма выделения цепей. Похоже, происходит зацикливание. Но выявить пока не получается. Альтернативный алгоритм мог бы быть построен на сканировании узлов и выделении начальных узлов цепочек. По некоторым признакам. А потом уже выделением всей цепочки через движение вперед. Вопрос: а всегда ли есть в цепочке признак начала? Теоретически, может и не быть. Цепочка при этом "отпадет" от графа, но такое может случиться, кажется... Этот же момент может быть и в моей реализации движения назад. Попробую это выявить.  

Выявил, гипотеза подтверждается. Я подумал и решил, что цикл можно разорвать тем, что проверять на попадание на текущий элемент при "движении назад".

Вроде получилось, зафиксирую последний результат. 
```
Hello de Brein!
lines:495108 words: 40333781 different: 23770815
Total 23166991 singles
Build nodes ok. Duration=22129
361676 chains
Build chains ok. Duration=1326
nchains=361676  maxchain=894
TGTCGCTGACCTATCCTGTAATCATTCTATAAGAAAATCCATTCCAAGAATATTTACTTAGATGTTATAATATTTATTATAACAAATTAAGGGATATTTATAAATTTGGGTATATCTCATAAGATACATATAAATATTAATATAATAATGCTGATTAATCTTAATATAACTACCATAAAGATATAATTTAACGCTTTTAATTTTTTTATCCACCGAATCCTTTACGACCATTATTAACTCATTCGTCATATTTTCTGTAATAAAGTAAGTTCCCCCAGGAACATTTTCTAGCAAACGATATATTAGACAACAATCTTCTGGAGGATGATAAAAATTTAGCTTTTTTAAATTCTTCCGTAATTTTTTTTCCTGGATTTTACGAGACCTACGATAAAATATACATTTTATCGGATTGCGAAATAACCTAACCATCTTCCTCGACTAACTAAGGATAGTTTCCTTATTTTAACAGTCATTAGAAATAAAGTTTATTACAAAATATATTAATTTTTTATAAAATTATTTCTTGTTAAAAATCATCATTTTTAATTGGAATCCTATTATAGACAATAAAATATCATTATTAGTAATAATTAAACGGCTCTAAATTTTAGTTCTTTGTCTTCAACTTAGAGGTCTAGTATAGGGTAGCCACTATGAAGGTGCTAATTCTAGTACTACTCGGGGTGGTTATCCTTCAGGCCGCACCTATACGTAAATTAGAAGATCTACTACCAACCCGTTATCCTCCTAAACATGAGCTGGTTTATTGGTGCACCTACGCAAATCAATGTGACTTTTGCTGGGAATGCGTCCACGGTATCTGCCGAAACAGGATTCAAGCAGATTGGCCAGTTATTCACCAAAATGACTGGATTATAAATTGCACGGTTTCCCGCTGGCTAAATAAATG
duration=1326
```
Максимальный захват памяти 4170 Мб. 

А как решать эту задачу по-другому? С помощью кластера. Есть 23 млн. узлов, в узле есть информация, напр. 10 байтов и две ссылки по 8 байтов, еще признак просмотренности. Итого, 27 байтов. Всего - меньше гигабайта. Приближаемся к человеческому геному. Но все же, с идеями напряженка.

Часть распределения по процессорам/задачам - отдельная работа с узлами и с графом. Действительно, содержимое узлов (код), при анализе графа нам не существенно. Если ссылки реализовывать целыми, то будет 2 целых и одно целое - ссылка на узел. 12 байтов. Всего 250 Мб. ОЗУ. Уже можно всю "человеческую" информацию загнать в один компьютер с ОЗУ в 50 Гб. Это также палеотив, надо все же распараллеливать. 

Рассмотрим множество ребер { исток, инфо, сток }. Я могу это индексировать. Тогда индекс Sources и Targets дадут возможность по заданному имени узла получать все истоковые или стоковые дуги.  

Попробую проанализировать задачу. Пусть огромные (больше объема ОЗУ) массивы данных накапливаются на мастере. Первый массив - множество пар { номер, код }. Чтобы можно было бы процесс распараллелить, номера не обязательно последовательные. В процессе сканирования ридов, берем очередной код, выполняем шардеринг и преобразуем его в номер. Пару записываем в последовательность. Сейчас обрабатывается 40 млн. слов за 20 сек. , т.е. 2 млн. запроса в сек. Теоретически, TCP дает возможность выполнять до 100 тыс. запросов в сек.

Итак, создание множества узлов и первичной системы дуг, потребуется работа распределенной таблицы имен в режиме одиночных запросов. Таблицу дуг надо индексировать. Индексирование можно сделать через массовую операцию и через кластер. Пусть есть множестов пар { source, target }, отправляем множество пар { source, na } на сортировку, получаем множество исключаемых пар, можем лишние дуги исключить простым сканированием, если это множество будет упорядочено по номеру пары (дуги). Далее, нужно движение по дугам. Соответственно, нужны распределенные индексы и динамика единичных запросов.

### 20190914 09:28
Начинаю проект DeBreinData. Это будет решение, соответствующее тому, которое есть в проекте DeBrein, но с ориентиацией на большие данные и кластер.

Первая часть работы построение графа. Сканирование файла ридов будет таким же, другим будет формируемый граф. Формируемый граф будет имитироваться key-value хранилищем, ссылки будут вперед и назад в виде кода узла. Кодом узла будет номер узла.  

Только узел придется разделить на части - часть это строковый код, а часть - ссылки и другие поля. Есть впечатление, что строковый код нужен редко и что хеш-таблица по нему нужна только в начале. Буду создавать эту таблицу как последовательность кодов. Пусть таблица будет [sstring], индекс по полю будет ...

Сколько будет "весить" первая хеш-таблица? Есть 500 тыс. ридов, каждый преобразуется в в порядка 100 узлов. Часть узлом может совпадать. В нашем случае, получилось порядка 24 млн. входов. Как обойтись без хеш-словаря? Можно отсортировать, но это будет не достаточно быстро. К тому же, досортировка будет делаться медленно. Хотя это путь... Другой вариант - распределенный словарь. Проблема - в сетевой "медленности" одиночных запросов. Нужны массовые запросы. В принципе, возможен дополнительный прогон. Сначала синтаксически разбрасываем по модулям, модули сортируют, формируя свои словари. Потом будем массово запрашивать и получать коды. Под этими кодами, мы сохраняем формируемые узлы. При появлении информациии, дописываем информацию в узлы. Как-то так...

Получается, что надо каждый модуль "снабдить" своим диапазоном кодов, при первом проходе, снабдит слова кодами и устранит дублирование. Распределенная система словарей будет выдавать по слову код и по коду слово. Собственно построение словаря будет производиться следующим образом: 
1. Есть анализируемая последовательность рида, мы находимся в   

### 20190915 07:27
Пока досыпал или просыпался, придумал модифицированное решение. Суть заключается в том, чтобы синтаксические свойства генерируемого идентификатора (кода) для узла, соответствовали синтаксическим свойствам слова. Это не только увеличит эффективность обработки, но и упростит логику всегно построения. Насчет эффективности обработки, возможно, я не прав. Была идея того, чтобы коды одного рида попадали в одну группу. Но при новом подходе это не получится. 

Попробую изложить логику обработки, соответствующую новому подходу. Теперь не надо делить сканирование массива ридов на проходы. Имеем предыдущий узел (если есть), имеем очередное слово, запрашиваем хранилище, получаем текуший узел. Далее, производим модификации узлов, предыдущий, если есть и если модифицирован, сохраняем, текущий делаем предыдущим или сохраняем, если он последний в риде и изменен. Процедура вполне понятна, но как насчет массового исполнения? Массовое исполнение получится за счет обработки нескольких ридов одновременно. Как это удобнее сделать?

Заводим объект рид и итеративно подвергаем его обработке по предложенной схеме. Множество обрабатываемых ридов будем пополнять по мере выхода ридов из обработки. 

А еще я подумал над синхронизацией. В предложенном варианте, когда "путешествует" запись объекта, синхронизацию будет осуществлять трудно. Несколько более сложная схема, позволит это делать надежно. Имеется ввиду посылка более определенной команды типа "в записи с кодом C значением V изменить поле pred". 

### 20190916 07:56
Если не сильно оптимизировать, то единичные команды к хранилищу будут:
```
int GetNodeId(string word);
void SetNodePrev(int node, int prevlink);
void SetNodeNext(int node, int nextlink);
```

### 20190918 10:01
Прошлым достижением было то, что удалось построить граф уже в идее key-value. Только пока без "распараллеливания". Почему-то обработка несколько замедлилась. Надо посмотреть почему.

При старом подходе, построение графа выполнялось 18 сек. и выделение цепочек выполнялось 1.3-1.4 сек. При новом подхоходе граф стрится 19-20 сек. И оперативной памяти в обех свариантах захватывалось около 4 Гб. Даже не буду заморачиваться с анализом... Теперь косвенно проверим результат. Проверить до конца не удалось, но пока проверял, исправил две ошибки, надеюсь, теперь будет все нормально. 

Последние параметры графа: число узлов 23770815, число ссылок на предудущий 23464396, число ссылок на следующий 23462285.

Буду трансформировать программу, а потом дописывать. Трансформация программы заключается в разбиении метода Process() на мелкие действия. Причем мелкие действия разных ветвей Process не мешают друг другу. Потом эи действия будем собирать в группы независимых действий и выполнять эти группы. 

Сделал приготовления в коде: убрал цикл в Process() и размельчил действия. Каждое обращение к хранилищу делается в конце обработки, следующие состояния прямо указываются. Теперь надо куда-то получить команду работы с хранилищем, эта команда должна быть снабжена также посылающим объектом Reed, в объекте найдется следующее состояние. Цикл обработки будет следующий: заглушка для команды выполняется, новое состояние устанавливается, а в исполнительнуя часть "уходит" объект Reed и команда для хранилища. 

### 20190919 08:45
Предположим, мы сделали буфер исполнения ридов. Буфер пополняется новыми ридами и освобождается от уже обработанных. Буфер работает "ортогонально" основному процессу. То есть, шаг обработки заключается в том, что исполняется шаг во всех (!) ридах и формируется "широкая" команда хранилищу. Посылаем команду, получаем "широкий" ответ. Элементы этого ответа в точности соответствуют буферу. Исполняем лямда-функции на этих значениях. Как-то так... Видно, что схема может быть более асинхронной и, может быть, более эффективной, но пока надо стремиться к простоте. 

Применил BufferredProcessing, результаты получились, но несколько отличные. В частности, число получившихся ссылок вперед и назад получилось где-то на 300 тыс. меньше в каждом направлении (269966 и 270115). 

Прогон графа reads7x3.txt дает: 30 слов, разных 14, 5 цепочек.

### 20190920 07:14
Почему получилось расхождение, я не выявил, проверил на малых данных, вроде соответствует...

Но теперь я придумал простую схему для реализации "горизонтальных" запросов к хранилищу. Суть идеи в том, что в каждом элементе Reed завести три поля: команда, аргументы и результат. Соотвественно, в рамках одного шага процесс заполняет два поля. Потом выполянется массовое обращение к хранилищу, потом процесс как-то фиксирует результат. Это можно сделать в виде дополнительного состояния и метода (Fix?). Но похоже, фиксировать лучше с помощью лямбда функции, точнее - Action. Попробую. 

Попробовал, сгруппировал горизонтальную обработку, пока работает. Теперь надо сделать удаленный запрос или его имитацию. TCP запрос будем делать по правилам Поляра. Это значит, что первые байты (8) - количество запросов, дальше идут запросы. Запрос имеет следующий тип:
```
Comm = Empty^None,
    GetNodeId^{ word: sstring },
    SetNodeNext^{ node: integer, nextlink: integer },
    SetNodePrev^{ node: integer, prevlink: integer };
```
Проблема описания в том, что тип результата надо указывать дополнительно. 

### 20190921 07:01
Теперь сделаю преобразование набора команд в поток (массив) байтов. Потом исполню этот массив, потом верну результат и преобразую назад. 

Кажется, технологический прототип я сделал. Без реальной передачи по сети, но с выделением всех этапов. Что получается? Для группирования обработки ридов по 1 тыс., мы получаем число обменов около 200 тыс. посылаемыми массивами в 22 тыс. байтов. Время полной обработки без дополнительного времени на коммуникации 54 сек. Что реально это означает пока не очень понятно потому что неизвестна скорость обмена массивами такой длины. Гипотетически, это могло бы быть около 6 сек. Но эти скорости (32 мс. на 1000 обменов порциями в 22 тыс. байтов) вряд ли достижимы в реальном обмене. В общем, надо проверять...

### 20190922 09:46
Программа получилась очень "корявая". И не факт, что правильная... А как писать красиво и эффективно? Анализ показывает, что я пытаюсь написать асинхронную программу синхронными средствами. Я разбиваю общий поток вычислений на шаги, комбинирую эти шаги, я меняю порядок вычислений. Если разбить программу на шаги s1, s2, s3, ..., а потом приметить программу к множеству аргументов, то может статься, что отдельные шаги для разных аргументов можно выполнять независимо или параллельно. Тогда я группирую шаги si(a), si(b), ... и выполняю их одновременно. Причем можно делать это синхронно, можно асинхронно. В частности, пул исполнения может уменьшаться за счет выполненных шагов и пополняться за счет продолжения  
Почитал про асинхронное программирование. Не очень понятно, особенно в контексте решаемой задачи. Но хочу попробовать сочинить прозрачный тест. Идея заключается в "проходе" прямоугольной матрицы. Пусть есть два числа: номер серии и номер шага. Программа запускается с каким-то номером серии и все значения этого потока будут иметь этот номер серии, но различные номера шагов. Можно также работать с элементами матрицы, где используются номер рядка и номер колонки. Для наглядности, значение шага будет вычислятья как ir * 1_000_000 + ic. ic меняется последовательно в рамках некоторого процесса.   